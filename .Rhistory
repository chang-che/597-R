if(diff<0){
stop('loglikelihood is no better than last iteration!')
}
if(diff<epsilon){
stop('Algorithm converges!')
}
gamma.log <- FB$alphalog+FB$betalog-LL
gamma.m <- exp(gamma.log)
alpha.hat <- FB$alpha_hat
beta.hat <- FB$beta_hat
mu.vec <- apply(gamma.m, 2, function(x) sum(x*Obser)/sum(x))
sd.vec <- sqrt(apply((matrix(obs.vec, nrow = Ti, ncol = N) - matrix(mean.vec,nrow = Ti, ncol = N, byrow = TRUE))^2 * gamma.m, MARGIN = 2,FUN = sum)/apply(gamma.m, MARGIN = 2, FUN = sum))
pi.mar <- gamma.m[1,]
tran.m <- (t(alpha.hat[1:Ti-1,])%*%(density.m[2:Ti,]*beta.hat[2:Ti,]))*tran.m #maybe a parenthesis is redundant.
tran.m <- t(scale(t(tran.m)))
}
for (iter in 1:maxiter){
FB <- ForwordBack(obs.vec, pi.mar, tran.m, mean.vec, sd.vec)
LL <- FB$Loglikelihood
log.lik.iter <- c(log.lik.iter, LL)
diff <- LL - oldLL
cat('iter=', iter, '\n')
cat('LL=', round(LL, 10), '\n')
cat('diff=', diff)
if(diff<0){
stop('loglikelihood is no better than last iteration!')
}
if(diff<epsilon){
stop('Algorithm converges!')
}
gamma.log <- FB$alphalog+FB$betalog-LL
gamma.m <- exp(gamma.log)
alpha.hat <- FB$alpha_hat
beta.hat <- FB$beta_hat
mu.vec <- apply(gamma.m, 2, function(x) sum(x*Obser)/sum(x))
sd.vec <- sqrt(apply((matrix(obs.vec, nrow = Ti, ncol = N) - matrix(mean.vec,nrow = Ti, ncol = N, byrow = TRUE))^2 * gamma.m, MARGIN = 2,FUN = sum)/apply(gamma.m, MARGIN = 2, FUN = sum))
pi.mar <- gamma.m[1,]
tran.m <- (t(alpha.hat[1:Ti-1,])%*%(density.m[2:Ti,]*beta.hat[2:Ti,]))*tran.m #maybe a parenthesis is redundant.
tran.m <- t(scale(t(tran.m)))
}
oldLL <- -Inf
log.lik.iter <- c(-Inf)
for (iter in 1:maxiter){
FB <- ForwordBack(obs.vec, pi.mar, tran.m, mean.vec, sd.vec)
LL <- FB$Loglikelihood
log.lik.iter <- c(log.lik.iter, LL)
diff <- LL - oldLL
cat('iter=', iter, '\n')
cat('LL=', round(LL, 10), '\n')
cat('diff=', diff)
if(diff<0){
stop('loglikelihood is no better than last iteration!')
}
if(diff<epsilon){
stop('Algorithm converges!')
}
gamma.log <- FB$alphalog+FB$betalog-LL
gamma.m <- exp(gamma.log)
alpha.hat <- FB$alpha_hat
beta.hat <- FB$beta_hat
mu.vec <- apply(gamma.m, 2, function(x) sum(x*Obser)/sum(x))
sd.vec <- sqrt(apply((matrix(obs.vec, nrow = Ti, ncol = N) - matrix(mean.vec,nrow = Ti, ncol = N, byrow = TRUE))^2 * gamma.m, MARGIN = 2,FUN = sum)/apply(gamma.m, MARGIN = 2, FUN = sum))
pi.mar <- gamma.m[1,]
tran.m <- (t(alpha.hat[1:Ti-1,])%*%(density.m[2:Ti,]*beta.hat[2:Ti,]))*tran.m #maybe a parenthesis is redundant.
tran.m <- t(scale(t(tran.m)))
}
sd.vec
tran.,
tran.m
tran.m <- matrix(unlist(x1), ncol = N, byrow = T)
mean.vec <- c(2,3,9,10)
sd.vec <- c(1.5,2,3,4)
oldLL <- -Inf
log.lik.iter <- c(-Inf)
for (iter in 1:maxiter){
FB <- ForwordBack(obs.vec, pi.mar, tran.m, mean.vec, sd.vec)
LL <- FB$Loglikelihood
log.lik.iter <- c(log.lik.iter, LL)
diff <- LL - oldLL
cat('iter=', iter, '\n')
cat('LL=', round(LL, 10), '\n')
cat('diff=', diff)
if(diff<0){
stop('loglikelihood is no better than last iteration!')
}
if(diff<epsilon){
stop('Algorithm converges!')
}
gamma.log <- FB$alphalog+FB$betalog-LL
gamma.m <- exp(gamma.log)
alpha.hat <- FB$alpha_hat
beta.hat <- FB$beta_hat
mu.vec <- apply(gamma.m, 2, function(x) sum(x*Obser)/sum(x))
sd.vec <- sqrt(apply((matrix(obs.vec, nrow = Ti, ncol = N) - matrix(mean.vec,nrow = Ti, ncol = N, byrow = TRUE))^2 * gamma.m, MARGIN = 2,FUN = sum)/apply(gamma.m, MARGIN = 2, FUN = sum))
pi.mar <- gamma.m[1,]
tran.m <- (t(alpha.hat[1:Ti-1,])%*%(density.m[2:Ti,]*beta.hat[2:Ti,]))*tran.m #maybe a parenthesis is redundant.
tran.m <- t(scale(t(tran.m)))
}
tran.m <- matrix(unlist(x1), ncol = N, byrow = T)
mean.vec <- c(2,3,9,10)
sd.vec <- c(1.5,2,3,4)
oldLL <- -Inf
log.lik.iter <- c(-Inf)
for (iter in 1:maxiter){
FB <- ForwordBack(obs.vec, pi.mar, tran.m, mean.vec, sd.vec)
LL <- FB$Loglikelihood
log.lik.iter <- c(log.lik.iter, LL)
diff <- LL - oldLL
cat('iter=', iter, '\n')
cat('LL=', round(LL, 10), '\n')
cat('diff=', diff, '\n')
if(diff<0){
stop('loglikelihood is no better than last iteration!')
}
if(diff<epsilon){
stop('Algorithm converges!')
}
gamma.log <- FB$alphalog+FB$betalog-LL
gamma.m <- exp(gamma.log)
alpha.hat <- FB$alpha_hat
beta.hat <- FB$beta_hat
mu.vec <- apply(gamma.m, 2, function(x) sum(x*Obser)/sum(x))
sd.vec <- sqrt(apply((matrix(obs.vec, nrow = Ti, ncol = N) - matrix(mean.vec,nrow = Ti, ncol = N, byrow = TRUE))^2 * gamma.m, MARGIN = 2,FUN = sum)/apply(gamma.m, MARGIN = 2, FUN = sum))
pi.mar <- gamma.m[1,]
tran.m <- (t(alpha.hat[1:Ti-1,])%*%(density.m[2:Ti,]*beta.hat[2:Ti,]))*tran.m #maybe a parenthesis is redundant.
tran.m <- t(scale(t(tran.m)))
}
View(gamma.m)
tran.m <- matrix(unlist(x1), ncol = N, byrow = T)
mean.vec <- c(2,3,9,10)
sd.vec <- c(1.5,2,3,4)
oldLL <- -Inf
log.lik.iter <- c(-Inf)
FB <- ForwordBack(obs.vec, pi.mar, tran.m, mean.vec, sd.vec)
FB$betalog
FB$beta_hat
FB$alpha_hat
ForwordBack <- function(ob.vec, pi.mar, tran.m, mean.vec, sd.vec){
N <- nrow(tran.m)
Ti <- length(ob.vec)
density.m <- matrix(rep(NA, Ti*N), nrow = Ti)
for (i in 1:Ti){
density.m[i,] <- mapply(
dnorm, 'x' = obs.vec[i], 'mean' = mean.vec, 'sd' = sd.vec, SIMPLIFY = T)
}
# Forward
alpha_b_h <- as.double(pi.mar)
alpha.log <- matrix(rep(NA, Ti*N), nrow = Ti)
alpha.hat <- matrix(rep(NA, Ti*N), nrow = Ti)
Ct.log <- as.double(0) # it is actually the minus log of Ct
for (i in 1:N){
if (i >1)
alpha_b_h <- alpha_b_h%*%tran.m
alpha_b_h <- pi.mar*density.m[i,] #now is bar, next becomes hat
alpha_sum <- sum(alpha_b_h)
alpha_b_h <- alpha_b_h/alpha_sum
Ct.log <- Ct.log + log(alpha_sum)
alpha.hat[i,] <- alpha_b_h
alpha.log[i,] <- log(alpha_b_h) + Ct.log
}
log.lik <- Ct.log
# backward
beta_b_h <- as.double(rep(1/N, N))
beta.log <- matrix(as.double(rep(0, N*Ti)), nrow = Ti)
beta.hat <- matrix(as.double(rep(0, N*Ti)), nrow = Ti)
Dt.log <- as.double(log(m))
for (i in (Ti-1):1){
beta_b_h <- tran.m%*%(density.m[i+1,]*beta_b_h)
beta.log[i,] <- log(beta_b_h) + Dt.log
beta_sum <- sum(beta_b_h)
beta_b_h <- beta_b_h/beta_sum
beta.hat[i,] <- beta_b_h
Dt.log <- Dt.log + log(beta_sum)
}
return(list(betalog = beta.log, alphalog = alpha.log, Loglikelihood = log.lik, alpha_hat = alpha.hat, beta_hat = beta.hat))
}
FB <- ForwordBack(obs.vec, pi.mar, tran.m, mean.vec, sd.vec)
FB$betalog
FB$beta_hat
FB$alpha_hat
alpha_b_h
source('~/My/math/STAT/Courses/AMS 597/597-R/FB.R', echo=TRUE)
FB <- ForwordBack(obs.vec, pi.mar, tran.m, mean.vec, sd.vec)
FB$betalog
FB$beta_hat
FB$alpha_hat
source('~/My/math/STAT/Courses/AMS 597/597-R/FB.R', echo=TRUE)
FB <- ForwordBack(obs.vec, pi.mar, tran.m, mean.vec, sd.vec)
pi.mar <- rep(1/N,N)
source('~/My/math/STAT/Courses/AMS 597/597-R/FB.R', echo=TRUE)
N <- 4
Ti <- length(obs.vec)
maxiter <- 500
epsilon <- 1e-6
pi.mar <- rep(1/N,N)
# transition matrix initial states
x1 = list()
for (i in 1:N) {
x <- runif(N)
x1[[i]] <- x/sum(x)
}
tran.m <- matrix(unlist(x1), ncol = N, byrow = T)
mean.vec <- c(2,3,9,10)
sd.vec <- c(1.5,2,3,4)
FB <- ForwordBack(obs.vec, pi.mar, tran.m, mean.vec, sd.vec)
FB$betalog
FB$beta_hat
FB$alpha_hat
apply(alpha.hat, 1, sum)
apply(FB$alpha_hat, 1, sum)
FB$alphalog
my.Sigma <- matrix(c(2,1,1,1,2,1,1,1,2),nrow=3)
eigen(my.Sigma, symmetric = T)
L <- chol(my.Sigma)
L
L%*%t(L)
my.Sigma <- matrix(c(2,1,1,1,2,1,1,1,2),nrow=3)
eigen(my.Sigma, symmetric = T)
L <- chol(my.Sigma)
L
My.Sigma ==L%*%t(L)
my.Sigma <- matrix(c(2,1,1,1,2,1,1,1,2),nrow=3)
eigen(my.Sigma, symmetric = T)
L <- chol(my.Sigma)
L
my.Sigma ==L%*%t(L)
my.Sigma <- matrix(c(2,1,1,1,2,1,1,1,2),nrow=3)
eigen(my.Sigma, symmetric = T)
L <- chol(my.Sigma)
L
my.Sigma ==t(L)%*%L
my.Sigma <- matrix(c(2,1,1,1,2,1,1,1,2),nrow=3)
eigen(my.Sigma, symmetric = T)
L <- chol(my.Sigma)
L
t(L)%*%L
my.Sigma ==t(L)%*%L
### generate multivariate normal using Cholesky decomposition ###
genmultv.chol <- function(n,mu,Sigma){
d <- length(mu)
Q <- chol(Sigma)
Z <- matrix(rnorm(n*d),nrow=n)
X <- Z%*%Q+matrix(rep(1,n),ncol=1)%*%t(mu)
return(X)
}
my.mu <- c(0,0,0)
my.Sigma <- matrix(c(2,1,1,1,2,1,1,1,2),nrow=3)
my.Xchol <- genmultv.chol(10000,my.mu,my.Sigma)
colMeans(my.Xchol)
##
apply(my.Xchol,2,mean)
cov(my.Xchol)
### generate multivariate normal using Cholesky decomposition ###
genmultv.chol <- function(n,mu,Sigma){
d <- length(mu)
Q <- chol(Sigma)
Z <- matrix(rnorm(n*d),nrow=n)
X <- Z%*%Q+matrix(mu, byrow = T, nrow = n)
return(X)
}
my.mu <- c(0,0,0)
my.Sigma <- matrix(c(2,1,1,1,2,1,1,1,2),nrow=3)
my.Xchol <- genmultv.chol(10000,my.mu,my.Sigma)
matrix(my.mu, nrow = 10, byrow = T)
matrix(my.mu, nrow = 10, byrow = F)
matrix(my.mu, nrow = 10, byrow = F)
matrix(my.mu, nrow = 10, ncol =3, byrow = F)
### generate multivariate normal using Cholesky decomposition ###
genmultv.chol <- function(n,mu,Sigma){
d <- length(mu)
Q <- chol(Sigma)
Z <- matrix(rnorm(n*d),nrow=n)
X <- Z%*%Q+matrix(mu, byrow = T, nrow = n, ncol = length(mu))
return(X)
}
my.mu <- c(0,0,0)
my.Sigma <- matrix(c(2,1,1,1,2,1,1,1,2),nrow=3)
my.Xchol <- genmultv.chol(10000,my.mu,my.Sigma)
colMeans(my.Xchol)
##
apply(my.Xchol,2,mean)
cov(my.Xchol)
x <- matrix(c(2,4,1,2), nrow = 2)
y <- svd(x)
x <- matrix(c(2,4,1,2), nrow = 2)
y <- svd(x)
y
solve(matrix(c(1,2,3,4), nrow = 2))
x <- c(1,2,3,4)
y <- solve(matrix(x, nrow = 2))
x%*%y
x <- matrix(c(1,2,3,4), nrow = 2)
y <- solve(x)
x%*%y
?solve
#loading the Splines Packages
require(splines)
#ISLR contains the Dataset
require(ISLR)
attach(Wage) #attaching Wage dataset
?Wage #for more details on the dataset
agelims<-range(age)
#Generating Test Data
age.grid<-seq(from=agelims[1], to = agelims[2])
#3 cutpoints at ages 25 ,50 ,60
fit<-lm(wage ~ bs(age,knots = c(25,40,60)),data = Wage )
summary(fit)
rm(list = ls())
dat <- read.delim('http://www.ams.sunysb.edu/~pfkuan/Teaching/AMS597/Data/Qn1Data.txt',header=T,sep='\t')
?permutate
??permutate
#2.
x <- runif(1000)
r.vec <- sqrt(-log(1-x))
#3.
Phi_inv <- function(size){
u = runif(size)
t2 <- -2*log(u)
t <- sqrt(t2)
x <- t-(2.30753+0.27061*t)/(1+0.99229*t+0.04481*t^2)
return(x)
}
rand_t <- function(size,df){
numerator <- Phi_inv(size)
z <- matrix(Phi_inv(size*df), ncol = df)
z <- z^2
w <- apply(z, 1, sum)
ans <- numerator/sqrt(w/df)
return(ans)
}
S <- sample(c(1:3),100,prob=c(0.3,0.35,0.35),replace=TRUE)
x <- rep(NA,100)
x[S==1] <- rand_t(length(which(S==1)),3)
x[S==2] <- rand_t(length(which(S==2)),5)
x[S==3] <- rand_t(length(which(S==3)),7)
library(FrF2)
PlanA = FrF2(nruns = 64, nfactor = 6)
x = desnum(PlanA)
class(x)
x.logical <- (x ==1)
?BIC
x.logical <- (x ==1)
B <- rep(NA, 64)
for (i in 1:64){
y <- x.logical[i,]
fit <- lm(dat[,1]~data[-1,y])
B[i] <- BIC(fit)
}
ind <- which(B == min(B))
B <- rep(NA, 64)
for (i in 1:64){
y <- c(F, x.logical[i,])
fit <- lm(dat[,1]~data[,y])
B[i] <- BIC(fit)
}
for (i in 1:64){
y <- c(F, x.logical[i,])
fit <- lm(dat[,1]~dat[,y])
B[i] <- BIC(fit)
}
dat <- as.data.frame(dat)
for (i in 1:64){
y <- c(F, x.logical[i,])
fit <- lm(dat[,1]~dat[,y])
B[i] <- BIC(fit)
}
x.logical[1,]
class(x.logical[1,])
as.vector(x.logical[1,])
for (i in 1:64){
y <- as.vector(c(F, x.logical[i,]))
fit <- lm(dat[,1]~dat[,y])
B[i] <- BIC(fit)
}
for (i in 1:64){
y <- as.vector(c(F, x.logical[i,]))
fit <- lm(dat[,1]~dat[y])
B[i] <- BIC(fit)
}
?lm
y <- as.vector(c(F, x.logical[1,]))
a <- dat[,y]
c(F, x.logical[1,])
View(dat)
View(a)
y <- as.vector(c(T, x.logical[1,]))
c(F, x.logical[1,])
a <- dat[,y]
for (i in 1:64){
y <- as.vector(c(T, x.logical[i,]))
a <- dat[,y]
fit <- lm(y~., data= a)
B[i] <- BIC(fit)
}
for (i in 1:64){
y <- as.vector(c(T, x.logical[i,]))
a <- dat[,y]
fit <- lm(y~. , a)
B[i] <- BIC(fit)
}
for (i in 1:64){
a1 <- as.vector(c(T, x.logical[i,]))
data1 <- dat[,a1]
fit <- lm(y~., data = data1)
B[i] <- BIC(fit)
}
for (i in 1:64){
a1 <- as.vector(c(T, x.logical[i,]))
data1 <- dat[,a1]
fit <- lm(y~., data1)
B[i] <- BIC(fit)
}
for (i in 1:64){
a1 <- as.vector(c(T, x.logical[i,]))
data1 <- dat[,a1]
fit <- lm(y~, data1)
B[i] <- BIC(fit)
}
for (i in 1:64){
a1 <- as.vector(c(T, x.logical[i,]))
data1 <- dat[,a1]
fit <- lm(y ~ ., data1)
B[i] <- BIC(fit)
}
for (i in 1:64){
a1 <- as.vector(c(T, x.logical[i,]))
data1 <- dat[,a1]
fit <- lm(y ~ ., data = data1)
B[i] <- BIC(fit)
}
fit <- lm(y ~ ., data = dat)
for (i in 1:64){
a1 <- as.vector(c(T, x.logical[i,]))
data1 <- dat[,a1]
fit <- lm(y ~ ., data = dat[,a1])
B[i] <- BIC(fit)
}
?lm
for (i in 1:64){
a1 <- as.vector(c(T, x.logical[i,]))
data1 <- dat[,a1]
fit <- aov(y ~ ., data = dat[,a1])
B[i] <- BIC(fit)
}
?array
x = array(dim = 3)
for (i in 1:64){
a1 <- as.vector(c(T, x.logical[i,]))
data1 <- dat[,a1]
x = x[, ,i]
}
x = array(dim = 3)
for (i in 1:64){
a1 <- as.vector(c(T, x.logical[i,]))
data1 <- dat[,a1]
x = x[, ,i]
}
for (i in 1:64){
a1 <- as.vector(c(T, x.logical[i,]))
data1 <- dat[,a1]
x[[i]] = data1
}
x = list()
for (i in 1:64){
a1 <- as.vector(c(T, x.logical[i,]))
data1 <- dat[,a1]
x[[i]] = data1
}
for (i in 1:64){
fit <- lm(y ~ ., data = x[[i]])
B[i] <- BIC(fit)
}
for (i in 1:64){
data0 <- x[[i]]
fit <- lm(y ~ ., data = data0)
B[i] <- BIC(fit)
}
x
View(x[[1]])
dat <- as.data.frame(dat)
for (i in 1:64){
a1 <- as.vector(c(T, x.logical[i,]))
data1 <- dat[,a1]
fit <- lm(y ~ ., data = data1)
B[i] <- BIC(fit)
}
data1 <- dat[,a1]
fit <- lm(y ~ ., data = data1)
?lm
rm('y')
fit <- lm(y ~ ., data = data1)
for (i in 1:64){
a1 <- as.vector(c(T, x.logical[i,]))
data1 <- dat[,a1]
fit <- lm(terms(y ~ ., data = data1), data = data1)
B[i] <- BIC(fit)
}
names(dat)
names(dat)[1] <- 'response'
names(dat)
library(FrF2)
PlanA = FrF2(nruns = 64, nfactor = 6)
x = desnum(PlanA)
class(x)
x.logical <- (x ==1)
B <- rep(NA, 64)
for (i in 1:64){
a1 <- as.vector(c(T, x.logical[i,]))
data1 <- dat[,a1]
fit <- lm(response ~ ., data = data1)
B[i] <- BIC(fit)
}
